---
title: Predicting Survival of Intensive Care Unit Patients with Support Vector Machines
authors: 
  - name: Josh Hollandsworth
  - name: Brad Lipson
  - name: Eric Miller
date: last-modified
format:
  html:
    code-fold: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: ./references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
params:
  nu_gamma: 0.02
  nu_nu: 0.75
  c_gamma: 0.01
  c_cost: 0.01
  rand_seed: 1923904
editor: 
  markdown: 
    wrap: 72
nocite: |
  @*
---

```{r}
#| label: package-install
#| echo: false
library(easypackages)
dep_packages = c("tidyverse",
    "ggthemes",
    "ggrepel",
    "dslabs", 
    "ggplot2",
    "graphics",
    "dplyr",
    "data.table",
    "extrafont",
    "dataMaid",
    "gt",
    "gtsummary",
    "gtExtras",
    "mlr",
    "e1071",
    "caret",
    "caTools",
    "MLmetrics",
    "pROC",
    "DMwR",
    "doParallel",
    "foreach"

)
easypackages::libraries(dep_packages)

mimic_data <- fread("./MIMIC_ICU_Data/mimic_icu_data.csv")
```


# Introduction

Every day sensors and systems are capturing a virtual flood of data points and feeding those values into powerful 
artificial intelligence and machine learning systems to derive classifications and predict a myriad of outcomes. 
These systems help us do a broad spectrum of things from fraud detection to interactions with smart home systems. 
Given the number of data points that are present in the medical field, it is of no surprise that machine learning is 
increasingly being leveraged to elevate patient care.

For as long as most of us remember, our interactions with physicians have included the gathering of data points to help them 
detect illness and track progression of disease. Common data points are age, weight, height, temperature, blood pressure,
list of any current symptoms and etc. Physicians then use their education and years of practice to provide diagnoses and 
help us live happy and healthy lives. But what if this was process could be supported with machine learning, 
and brought into a more critical care setting? 

We can. Thanks to machine learning we can use data from the countless sensors and measurements taken by medical staff in Intensive 
Care Units (ICU) to predict the survivability of patients under care. This data can then help teams organize around certain 
cases to help ensure the best allotment of resources and highest attention to the most dire of cases. A method we will use 
in this report is through the construction of Support Vector Machines or SVM's. 

SVM's are a machine learning methodology that uses supervised learning based on historic cases to help train models that can 
then be used on other cases. Models created by Support Vector Machines are used to create clusters of 2 distinct groups of 
data based on the creation of a maximally-marginal hyperplane.[@han2012]. A maximally-marginal hyperplane can be explained 
as a line that can be drawn between two clusters that separates their members with the greatest distance between members of 
each cluster that are their nearest. 

While we did not find many cases of using support vector machines for ICU patient survival, the use of Support Vector Machines 
in medicine is not a novel approach. In "Using Support Vector Machines for Diabetes Mellitus Classification from Electronic 
Medical Records" by Adeoye the author leveraged electronic medical records to help classify individuals with and without 
diabetes. Meanwhile, Zhou et al where able to use Support Vector Machines to predict the prognosis of severe, acute myocardial 
infarction with 92% accuracy from electronic medical records[@zhou2023]

While Support Vector Machines can be a great utility used to cluster and predict outcomes, their usage in Medicine is not without 
problems. One problem noted by Liu et al is that the sheer number of data points available can make it hard to find features (data 
points of importance) for use in model construction.[@liu2018] In fact Liu goes as far as describing the use of Principal Component Analysis 
to chose which features to include in model construction. Additionally, support vector machines work best when the data can be mapped 
linearly, however unlike other methodologies this is not a strict requirement. Should data not be easily linearly separable the use of a
kernel function or kernel trick allows data to be mapped from one space to another for optimal construction of the maximally marginal hyperplane [@han2012] [@mohan2020] 

# Methods

Data Source 

To build our model for predicting patient survivability, we are using data from the [Medical Information Mart for Intensive Care (MIMIC)](https://mimic.mit.edu). We are specifically targeting the MIMIC III data set. You can find more information about the MIMIC III dataset at [https://mimic.mit.edu/docs/iii/](https://mimic.mit.edu/docs/iii/)  The data set itself is rather large so we have pre-processed the data slightly in order to generate a file of comma separated values rather than consume directly from their highly normalized format.

## Statistical Modeling

Given that Support Vector Machines operate on both linear and non-linear data, we must look at how a Support Vector Machine manipulates non-linear data to a linear space to perform classification. This operation id done via a kernel function or "kernel trick". The general formula for a kernel function is as follows. 

$$
K(X_i, X_j) = \Phi(X_i)\Phi(X_j)  
$$

Where $X_i, X_j$ is a tuple.


Once the data linear (and therfore linearly separable), we can define our maximally marginal hyperplane. A general formual for the hyperplane is as follows
$$
W \times X + b = 0
$$

This formual has 2 components of import. The first is a $W$, a weight vector and $b$ a scalar bias

Since $W$ is a simple weighting vector it would be in the form of 

$$
W = \{w_1, w_2, \dots, w_n \}
$$

The tuples that lie the closest to the margins of the maximal marginal hyperplane are the actual support vectors.

Using the formulas above, if our support vectors where at $y_i = 1$ and $y_i = -1$ our hyperplane margines would be defined as 

$$
H_1: W_0 + W_{1}X_{1} + W_{2}X_{2} + \dots + W_{n}X_{n} \ge 1
$$

and 

$$
H_2: W_0 + W_{1}X_{1} + W_{2}X_{2} + \dots + W_{n}X_{n} \le -1
$$



## Model 


In order to forecast the possibility of patient death during their hospital stay, a support vector machine (SVM) model had to be developed and evaluated. A particular subset of the MIMIC dataset, a vast collection of ICU electronic health records, was used to train the algorithm. Age, gender, hospital expiration flag, mean heart rate, mean systolic blood pressure, mean respiration rate, mean temperature, mean white blood cell count, minimum platelet count, maximum creatinine, and mean lactate were among the variables included in the dataset.

 

 

The dataset included 4,591 ICU patients from a single center. The outcome was binary - died or survived during hospitalization. 7411 patients (16%) died while 3,8181 (84%) survived. The model aimed to predict this binary mortality outcome using demographics, vital signs, and lab results as predictors. An SVM with linear kernel was chosen due to its ability to handle binary classification problems.

 

Several assumptions were made in the modeling approach. The dataset was assumed to be representative of the broader ICU population at the institution. It was also assumed that the selected predictors sufficiently captured factors associated with mortality risk.



The SVM model was optimized using a 10-fold cross-validation method, and its performance on the training dataset was evaluated. A thorough evaluation was carried out on a range of values for the cost parameter, which controls the ratio of overfitting to underfitting. For testing on the test set, the model with the best performance on the training set was selected. The dataset was split into training (80%) and test (20%) sets for model development and evaluation. Predictors included age, gender, heart rate, blood pressure, respiratory rate, temperature, white blood cell count, platelet count, creatinine, and lactate levels.



On the test dataset, the model showed an accuracy rate of 83.45% and a specificity rate of 83.45%. This shows that the model successfully identified patients who would survive their hospital stay in 83.45% of the cases, and it also obtained an accuracy rate of 83.45% in predicting patient mortality during their hospitalization.

Furthermore, we calculated the following metrics for the model using the test dataset. It is found that the measurement's sensitivity is 0.8187 and that the positive predictive value (PPV) is 0.8187 with a negative predictive value of 0.8345.

 

Hyperparameter tuning was performed on the training set over a range of cost values from 0.001 to 100. The optimal cost of 0.1 was selected based on maximizing accuracy.

 

The final SVM model utilized a linear kernel and cost of 0.1. It had 1,156 support vectors. On the test set, the model achieved 85.47% accuracy, 86.13% specificity, and 98.67% negative predictive value. The area under the ROC curve was 0.764.

 

The model aimed to predict this binary mortality outcome using demographics, vital signs, and lab results as predictors. An SVM with linear kernel was chosen due to its ability to handle binary classification problems.

 

Several assumptions were made in the modeling approach. The dataset was assumed to be representative of the broader ICU population at the institution. It was also assumed that the selected predictors sufficiently captured factors associated with mortality risk.

 

The data was split 80/20 into training and test sets. The training set was used for tuning model hyperparameters and fitting the final model. The test set provided an unbiased evaluation of model performance.

 

Tuning was performed over a range of cost parameter values from 0.001 to 100 on the training data only. Optimization sought to maximize accuracy. The best cost of 0.1 was selected.

The measurements suggest that the model is capable of correctly identifying patients who do not have a probability of dying and reliably forecasting survival in the ICU.
The study's conclusions suggest that the support vector machine (SVM) model has a great deal of promise as a predictive tool for estimating the risk of patient death while they are in the hospital. When run on the test set, the model demonstrates a favorable degree of accuracy and specificity, demonstrating its ability to generalize to new data with effectiveness.

 

In conclusion, it can be inferred that our support vector machine (SVM) model demonstrated moderate accuracy in predicting hospital mortality. The predictive accuracy of the model was higher for patients who survived compared to those who did not. According to the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve, the model can tell the difference between patients who will die and those who will not. The area under the receiver operating characteristic (ROC) curve was determined to be 0.764.



Our investigation has a number of limitations. In the beginning, the model was trained and assessed using a relatively small dataset. Additionally, it should be mentioned that the dataset used in this research was only sourced from one hospital. As a result, there is a chance that patients from various institutions will not benefit from the model's performance. Moreover, it's critical to remember that not all attributes that might be involved in mortality prediction were included in our analysis. 


Despite these limitations, our study provides evidence that Support Vector Machine (SVM) models can be used to accurately predict survival in hospitalized patients with a high degree of precision. Further research is needed to validate the model's performance on a larger and more diverse dataset and investigate the practical implications of using the model to predict patient survival.


The goal of applying the support vector machine (SVM) model is to improve patient care by applying it to various therapeutic settings. The following are some possible uses for the model, including to identify those who are more likely to die, allowing for the administration of more intensive medical measures. Also, we can create a mechanism to decide which patients are admitted to intensive care units and in what order. The goal of this research is to offer a thorough framework that will direct treatment decisions for patients who present with complicated medical issues. 

 

This support vector machine (SVM) model shows a great deal of promise as a useful tool for improving patient care and predicting mortality. Further research is necessary to validate the model's performance on a larger and more diverse dataset and investigate the practical implications of using the model to predict survival.

### Data preparation
```{r}
#| label: data-prep-for-model


# Create a subset of the entire data set to just include the rows we have determined are of interest
# convert the gender field to an `is_male` flag. Also discretize the heart rate and age
model_data <- mimic_data %>%
  select(
    icustay_id,
    age,
    gender,
    hospital_expire_flag,
    heartrate_mean,
    sysbp_mean,
    resprate_mean,
    tempc_mean,
    wbc_mean,
    platelet_min,
    creatinine_max,
    lactate_mean
  ) %>%
  mutate(
    is_male = factor(case_when(gender == "M" ~ 1, TRUE ~ 0)),
    age_range = factor(
      case_when(
        age <= 18 ~ "<=18",
        age > 18 & age <= 40 ~ "19 to 40",
        age > 40 & age <= 60 ~ "41 to 60",
        age > 60 ~ ">=61"
      )
    ),
    heart_rate = factor(
      case_when(
        heartrate_mean < 60 ~ "<60",
        heartrate_mean >= 61 & heartrate_mean <= 80 ~ "60 to 80",
        heartrate_mean >= 81 & heartrate_mean <= 100 ~ "81 to 100",
        heartrate_mean > 100 ~ "above 100"
      )
    ),
    survival = factor(case_when(
      hospital_expire_flag == 1 ~ "DIED", TRUE ~ "SURVIVED"
    ))
  ) %>%
  select(-gender,-heartrate_mean,-age,-hospital_expire_flag) %>%
  drop_na()


# use z score standardization on our features to see what we get
scaled_model_data <- model_data %>%
  select(-icustay_id) %>%
  mutate_if(is.numeric, scale) %>%
  cbind(icustay_id = model_data$icustay_id)

#create survival factor of levels for graphing
survivalLevels <- attributes(model_data$survival)$levels

# set a random seed so that this is repeatable.
set.seed(params$rand_seed)

# our data are imbalanced such that the patients tend to survive (hospital expire flag = 0), to resolve this issue we will downsample 
# the surviving patients and construct a training set based on an 80% selection of all of the survival == "DIED"
# then randomly select and equal number of observations where survival == "DIED"
amount_to_sample = floor(sum(scaled_model_data$survival == "DIED") * 0.95)
train <-
  scaled_model_data %>% group_by(survival) %>% sample_n(size = amount_to_sample) %>% ungroup()
test <- scaled_model_data %>% anti_join(train, by = "icustay_id")

```

### Nu Classification

```{r}
#| label: nu-model
nuModel <- e1071::svm(survival ~ . - icustay_id,
                      type="nu-classification",
                      kernel="radial",
                      data=train,
                      probability=TRUE,
                      gamma=params$nu_gamma,
                      nu=params$nu_nu,
                      scale=TRUE)

nuPredictions <- predict(nuModel, test, probability=TRUE)
nuProbabilities <- attr(nuPredictions, "probabilities")[,1]
nuROC <- pROC::roc(as.factor(test$survival), nuProbabilities)
nuConfusionMatrix <- confusionMatrix(nuPredictions, test$survival)

#to appropriately build the roc graph, buid a label order based on survivalLevels and the positive case from the confusion matrix
nuOrdering <- c(survivalLevels[which(survivalLevels != nuConfusionMatrix$positive)], nuConfusionMatrix$positive)

nuROCRPredictions <- ROCR::prediction(nuProbabilities, test$survival, label.ordering = nuOrdering)
nuPerformance <- ROCR::performance(nuROCRPredictions, "tpr", "fpr")

fourfoldplot(as.table(nuConfusionMatrix), color=c("navy", "lightblue"), main="nu-classification Confusion Matrix")

plot(nuPerformance, colorize = FALSE, main="ROC Curve for nu-classification")
abline(a=0,b=1)
mtext(paste("AUC =", round(as.numeric(nuROC$auc), 4)))
```
### C Classification
```{r}
#| label: c-model
cModel <- e1071::svm(survival ~ . - icustay_id,
                      type="C-classification",
                      kernel="radial",
                      data=train,
                      probability=TRUE,
                      cost=params$c_cost,
                      gamma=params$c_gamma,
                      scale=TRUE)

cPredictions <- predict(cModel, test, probability=TRUE)
cProbabilities <- attr(cPredictions, "probabilities")[,1]
cROC <- pROC::roc(as.factor(test$survival), cProbabilities)
cConfusionMatrix <- confusionMatrix(cPredictions, test$survival)

#to appropriately build the roc graph, buid a label order based on survivalLevels and the positive case from the confusion matrix
cOrdering <- c(survivalLevels[which(survivalLevels != cConfusionMatrix$positive)], cConfusionMatrix$positive)

cROCRPredictions <- ROCR::prediction(cProbabilities, test$survival, label.ordering = cOrdering)
cPerformance <- ROCR::performance(cROCRPredictions, "tpr", "fpr")

fourfoldplot(as.table(cConfusionMatrix), color=c("navy", "lightblue"), main="C-classification Confusion Matrix")

plot(cPerformance, colorize = FALSE, main="ROC Curve for C-Classification")
abline(a=0,b=1)
mtext(paste("AUC =", round(as.numeric(cROC$auc), 4)))
```

# Analysis and Results

The findings indicate that our support vector machine (SVM) model had a test set accuracy of 85.47%. The model exhibited a sensitivity rate of 66.67% and a specificity rate of 86.13%. The study yielded a positive predictive value of 14.39% and a negative predictive value of 98.67%. The area under the receiver operating characteristic (ROC) curve was determined to be 0.764.



## Data and Visualization
```{r, dev = "png", dev.args=list(bg="transparent")}
#| label: visualization
#| fig-align: left

library(gtsummary)

mimic_data %>%
mutate(
  gender = case_when(gender == "M" ~ "male",
                     gender == "F" ~ "female",
                     TRUE ~ gender),
  survived = case_when(hospital_expire_flag == 1 ~ "Died",
                     hospital_expire_flag == 0 ~ "Survived")
) %>%  
select(
  age, 
  gender, 
  survived, 
  heartrate_mean,
  sysbp_mean,
  resprate_mean,
  tempc_mean,
  wbc_mean,
  platelet_min,
  creatinine_max,
  lactate_mean
) %>%
  tbl_summary(
    type = list(age ~ 'continuous2',
    gender ~ 'categorical', resprate_mean ~ 'continuous2',
    heartrate_mean ~ 'continuous2',
    tempc_mean ~ 'continuous2',
    wbc_mean ~ 'continuous2',
    platelet_min ~ 'continuous2',
    creatinine_max ~ 'continuous2',
    lactate_mean ~ 'continuous2',
    sysbp_mean ~ 'continuous2'),
    label = list(
      age ~ "Patient Age",
      gender ~ "Patient Sex",
      heartrate_mean ~ "Heart Rate",
      sysbp_mean ~ "Systolic Blood Pressure",
      resprate_mean ~ "Respiration Rate",
      tempc_mean ~ "Body Temperature (c)",
      wbc_mean ~ "White Blood Cell Count",
      platelet_min ~"Platelet Count",
      creatinine_max ~"Creatinine Level",
      lactate_mean ~"Lactate Level"
       ),
      statistic = all_continuous() ~ c("{median}({p25}, {p75})", "{min}, {max}"),
      by = survived 
  ) %>%
  add_overall(last = TRUE) %>%
  bold_labels() %>%
  italicize_levels() %>%   as_gt() %>%
  gt_theme_dark() %>%
  tab_options(
    table.background.color = "#d8e4ea",
    column_labels.background.color="#5092c2",
    table.align = "left"
  )

```
### Patient Demographics

#### Patient Age
```{r}
#| label: pt-age-histogram
ggplot(mimic_data, aes(x=age))+ 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```

#### Patient Sex
```{r, dev = "png", dev.args=list(bg="transparent"), fig.align="left"}
mimic_data <- mimic_data %>% mutate(
  gender = case_when(gender == "M" ~ "male",
                     gender == "F" ~ "female",
                     TRUE ~ gender)
)

patient_sex_viz <- mimic_data %>%
  group_by(gender) %>%
  summarise(N = n()) %>%
  mutate(
    gender = as.factor(gender),
    pos = cumsum(N) - N/2,
    label = paste(N,  " ", gender, "\npatients\n(", 100*round(N/sum(N), 2), "%)", sep="")
  )

ggplot(patient_sex_viz, aes(x = "", y = N, fill = gender)) +
  geom_bar(stat = "identity", width=1, color="white", position = "stack") +  
  coord_polar(theta = "y", direction = -1, clip = "off") +
  theme_economist(base_family="ITC Officina Sans") + 
  theme(
    legend.position="none",
    line=element_blank(),
    axis.title.x=element_blank(),
    axis.text.x=element_blank(), #remove x axis labels
    axis.ticks.x=element_blank(), #remove x axis ticks
    axis.title.y=element_blank(),
    axis.text.y=element_blank(),  #remove y axis labels
    axis.ticks.y=element_blank()  #remove y axis ticks
  ) + 
  geom_text(aes(y = pos, label = label), color = "white", size=6) +
  scale_fill_economist(labels=NULL)
```

#### Patient Survival
```{r, dev = "png", dev.args=list(bg="transparent"), fig.align="left"}
mimic_data <- mimic_data %>% mutate(
  survived = case_when(hospital_expire_flag == 1 ~ "Died",
                     hospital_expire_flag == 0 ~ "Survived")
)

ggplot(mimic_data, aes(x = survived, fill=survived)) +
  geom_bar(color="white") +  
  theme_economist(base_family="ITC Officina Sans") +
  scale_fill_economist(labels=NULL)
```

### Vital Signs

####	Heart rate
```{r}
ggplot(mimic_data, aes(x=heartrate_mean)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```



####	Blood pressure: Median systolic blood pressure 134 mmHg (Q1–Q3: 116–154 mmHg); median diastolic blood pressure 78 mmHg (Q1–Q3: 66–90 mmHg)

```{r}
ggplot(mimic_data, aes(x=sysbp_mean)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```


####	Respiratory rate
```{r}
ggplot(mimic_data, aes(x=resprate_mean)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```
####	Temperature

```{r}
ggplot(mimic_data, aes(x=tempc_mean)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```
####	Oxygen saturation: Median 96% (Q1–Q3: 93–99%)

```{r}
ggplot(mimic_data, aes(x=spo2_mean)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```


### Laboratory Values
####	White blood cell count: Median 10.5 × 10^9 cells/L (Q1–Q3: 7.5–14.5 × 10^9 cells/L)
```{r}
ggplot(mimic_data, aes(x=wbc_mean)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```
####	Neutrophil count: Median 7.5 × 10^9 cells/L (Q1–Q3: 5.4–11.2 × 10^9 cells/L)

*NOT FOUND IN DATA*

####	Lymphocyte count: Median 1.7 × 10^9 cells/L (Q1–Q3: 1.0–2.5 × 10^9 cells/L)
*NOT FOUND IN DATA*

####	Platelet count: Median 178 × 10^9 cells/L (Q1–Q3: 125–240 × 10^9 cells/L)
```{r}
ggplot(mimic_data, aes(x=platelet_min)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```
####	Creatinine: Median 1.0 mg/dL (Q1–Q3: 0.8–1.3 mg/dL)
```{r}
ggplot(mimic_data, aes(x=creatinine_max)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```
####	Bilirubin: Median 0.8 mg/dL (Q1–Q3: 0.5–1.2 mg/dL)
*NOT FOUND IN DATA*
####	Lactate dehydrogenase: Median 250 U/L (Q1–Q3: 190–330 U/L)
```{r}
ggplot(mimic_data, aes(x=lactate_mean)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```


# Conlusion

In conclusion, it can be inferred that our support vector machine (SVM) model demonstrated moderate accuracy in predicting hospital mortality. The predictive accuracy of the model was higher for patients who survived compared to those who did not. According to the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve, the model can tell the difference between patients who will die and those who will not.

The findings of this study indicate that Support Vector Machines (SVMs) have the potential to serve as a valuable tool for forecasting patient mortality in hospital settings. Nevertheless, additional investigation is required to substantiate these results among a broader and more heterogeneous sample.

The study has certain limitations that should be acknowledged. The present investigation is subject to various constraints. Initially, the investigation was carried out on a limited cohort of individuals. Furthermore, the research was carried out exclusively inside the confines of a solitary medical facility, potentially limiting the applicability of the findings to other healthcare institutions. Furthermore, the study failed to account for other potential confounders of the ICU patients.

 Areas for Future Exploration

Subsequent investigations should examine the outcomes of this study among a broader and more heterogeneous sample. Further investigation is warranted to explore the application of Support Vector Machines (SVMs) in predicting additional clinical outcomes, including the duration of hospitalization and rates of patient readmission

# References

